{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mmvv11/recommender-colab/blob/main/3_NCF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "119ab203",
      "metadata": {
        "id": "119ab203"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.backends.cudnn as cudnn"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4331e385",
      "metadata": {
        "id": "4331e385"
      },
      "source": [
        "하이퍼파라미터"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27ed21e0",
      "metadata": {
        "id": "27ed21e0"
      },
      "outputs": [],
      "source": [
        "device=\"cuda\" # 디바이스\n",
        "n_neg=4 # 네거티브 샘플링 갯수\n",
        "n_layers = 3 # MLP 레이어 갯수\n",
        "dropout=0.0 # dropout rate\n",
        "data_path = \"./ml-100k_splited.pkl\" # 데이터셋 경로\n",
        "batch_size = 1024 # 훈련 데이터 배치 사이즈\n",
        "emb_size = 8 # MF 임베딩 크기\n",
        "lr = 1e-3\n",
        "top_k = 20\n",
        "n_epoch=10"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f22c43b",
      "metadata": {
        "id": "4f22c43b"
      },
      "source": [
        "## 데이터 로딩"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03ccd4f9",
      "metadata": {
        "id": "03ccd4f9"
      },
      "outputs": [],
      "source": [
        "with open(data_path, \"rb\") as f:\n",
        "    data = pickle.load(f)\n",
        "\n",
        "train, val, test, all_items, user2id, id2user, item2id, id2item = data.values()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db750558",
      "metadata": {
        "id": "db750558"
      },
      "outputs": [],
      "source": [
        "class MLDataset(Dataset):\n",
        "    def __init__(self, df, all_items, n_neg=4):\n",
        "        super().__init__()\n",
        "        self.n_neg=n_neg\n",
        "        self.users, self.items, self.labels = self.get_data(df, all_items)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.users)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.users[idx], self.items[idx], self.labels[idx]\n",
        "\n",
        "    def get_data(self, df, all_items):\n",
        "        users, items, labels = [], [], []\n",
        "        user_item_set = set(zip(df['user'], df['item']))\n",
        "        for u, i in user_item_set:\n",
        "            users.append(u)\n",
        "            items.append(i)\n",
        "            labels.append(1)\n",
        "            for _ in range(self.n_neg):\n",
        "                neg_item = np.random.choice(all_items)\n",
        "                while (u, neg_item) in user_item_set:\n",
        "                    neg_item = np.random.choice(all_items)\n",
        "                users.append(u)\n",
        "                items.append(neg_item)\n",
        "                labels.append(0)\n",
        "        return torch.tensor(users).to(device), torch.tensor(items).to(device), torch.tensor(labels, dtype=torch.float32).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5975a7a",
      "metadata": {
        "id": "c5975a7a"
      },
      "outputs": [],
      "source": [
        "train_dataset = MLDataset(train, all_items, )\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65491bb2",
      "metadata": {
        "id": "65491bb2"
      },
      "outputs": [],
      "source": [
        "user_consumed = train.groupby(\"user\")['item'].apply(list).to_dict()\n",
        "val_true = val.groupby(\"user\")['item'].apply(list).to_dict()\n",
        "test_true = test.groupby(\"user\")['item'].apply(list).to_dict()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f4f89d1",
      "metadata": {
        "id": "6f4f89d1"
      },
      "source": [
        "# 모델링"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8980a96",
      "metadata": {
        "id": "f8980a96"
      },
      "outputs": [],
      "source": [
        "class NCF(nn.Module):\n",
        "    def __init__(self, n_users, n_items, emb_size, n_layers):\n",
        "        super().__init__()\n",
        "        # GMF layer\n",
        "        self.emb_user = nn.Embedding(n_users, emb_size)\n",
        "        self.emb_item = nn.Embedding(n_items, emb_size)\n",
        "\n",
        "        # MLP layer\n",
        "        self.emb_user_MLP = nn.Embedding(n_users, emb_size*(2**(n_layers-1)))\n",
        "        self.emb_item_MLP = nn.Embedding(n_items, emb_size*(2**(n_layers-1)))\n",
        "        MLP = []\n",
        "        for i in range(n_layers):\n",
        "            input_size = emb_size*(2**(n_layers-i))\n",
        "            MLP.append(nn.Dropout(p=dropout))\n",
        "            MLP.append(nn.Linear(input_size, input_size//2))\n",
        "            MLP.append(nn.ReLU())\n",
        "        self.MLP_layer = nn.Sequential(*MLP)\n",
        "\n",
        "        # prediction layer\n",
        "        self.predict_layer = nn.Linear(emb_size*2, 1)\n",
        "\n",
        "        self._init_weight()\n",
        "\n",
        "    def _init_weight(self):\n",
        "        nn.init.normal_(self.emb_user.weight, std=1e-2)\n",
        "        nn.init.normal_(self.emb_item.weight, std=1e-2)\n",
        "        nn.init.normal_(self.emb_user_MLP.weight, std=1e-2)\n",
        "        nn.init.normal_(self.emb_item_MLP.weight, std=1e-2)\n",
        "\n",
        "        for m in self.MLP_layer:\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_uniform_(m.weight)\n",
        "        nn.init.kaiming_uniform_(self.predict_layer.weight, a=1, nonlinearity=\"sigmoid\")\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Linear) and m.bias is not None:\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def forward(self, user, item):\n",
        "        emb_user = self.emb_user(user)\n",
        "        emb_item = self.emb_item(item)\n",
        "        output_GMF = emb_user*emb_item\n",
        "\n",
        "        emb_user_MLP = self.emb_user_MLP(user)\n",
        "        emb_item_MLP = self.emb_item_MLP(item)\n",
        "        concat_emb_MLP = torch.cat((emb_user_MLP, emb_item_MLP), dim=1)\n",
        "        output_MLP = self.MLP_layer(concat_emb_MLP)\n",
        "\n",
        "        concat_output = torch.cat((output_GMF, output_MLP), dim=1)\n",
        "\n",
        "        prediction=self.predict_layer(concat_output)\n",
        "        return prediction.view(-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "442f12b2",
      "metadata": {
        "id": "442f12b2"
      },
      "source": [
        "모델, 손실 함수, 옵티마이저 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1935f00a",
      "metadata": {
        "id": "1935f00a"
      },
      "outputs": [],
      "source": [
        "n_users, n_items = len(user2id), len(item2id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8dc392a1",
      "metadata": {
        "id": "8dc392a1"
      },
      "outputs": [],
      "source": [
        "model = NCF(n_users, n_items, emb_size, n_layers)\n",
        "model.to(device)\n",
        "\n",
        "loss_function = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "41e024b9",
      "metadata": {
        "id": "41e024b9"
      },
      "source": [
        "메트릭\n",
        "* precision\n",
        "* recall\n",
        "* nDCG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1b61a75",
      "metadata": {
        "id": "e1b61a75"
      },
      "outputs": [],
      "source": [
        "def get_precision(pred, true, k=20):\n",
        "    intersection = set(pred).intersection(set(true))\n",
        "    return len(intersection)/ k\n",
        "\n",
        "def get_recall(pred, true, k=20):\n",
        "    intersection = set(pred).intersection(set(true))\n",
        "    return len(intersection)/len(true)\n",
        "\n",
        "def get_nDCG(pred, true, k=20):\n",
        "    intersection, _, idx_in_pred = np.intersect1d(true, pred, assume_unique=True, return_indices=True)\n",
        "    if intersection.size == 0:\n",
        "        return 0\n",
        "    rank_list = np.zeros(k, np.float32)\n",
        "    rank_list[idx_in_pred] = 1\n",
        "    ideal_list = np.sort(rank_list)[::-1]\n",
        "    dcg = np.sum(rank_list/np.log2(np.arange(2, k+2)))\n",
        "    idcg = np.sum(ideal_list /np.log2(np.arange(2, k+2)))\n",
        "    return dcg/idcg"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35389cb5",
      "metadata": {
        "id": "35389cb5"
      },
      "source": [
        "train process 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c97e5dc7",
      "metadata": {
        "id": "c97e5dc7",
        "outputId": "a484592d-5d45-46de-9919-3bd707b767fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 391/391 [00:07<00:00, 52.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1, total_loss: 0.4316\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "eval: 100%|██████████| 943/943 [00:02<00:00, 329.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "recall:0.2012\n",
            "precision:0.0978\n",
            "ndcg:0.3891\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 391/391 [00:05<00:00, 66.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 2, total_loss: 0.3549\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "eval: 100%|██████████| 943/943 [00:01<00:00, 503.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "recall:0.2630\n",
            "precision:0.1101\n",
            "ndcg:0.4295\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 391/391 [00:06<00:00, 59.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 3, total_loss: 0.3259\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "eval: 100%|██████████| 943/943 [00:01<00:00, 490.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "recall:0.2748\n",
            "precision:0.1155\n",
            "ndcg:0.4395\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 391/391 [00:06<00:00, 62.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 4, total_loss: 0.3084\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "eval: 100%|██████████| 943/943 [00:02<00:00, 415.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "recall:0.2788\n",
            "precision:0.1183\n",
            "ndcg:0.4522\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 391/391 [00:06<00:00, 62.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 5, total_loss: 0.2977\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "eval: 100%|██████████| 943/943 [00:01<00:00, 519.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "recall:0.2860\n",
            "precision:0.1203\n",
            "ndcg:0.4566\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 391/391 [00:07<00:00, 55.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 6, total_loss: 0.2894\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "eval: 100%|██████████| 943/943 [00:01<00:00, 516.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "recall:0.2867\n",
            "precision:0.1204\n",
            "ndcg:0.4592\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 391/391 [00:06<00:00, 58.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 7, total_loss: 0.2826\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "eval: 100%|██████████| 943/943 [00:01<00:00, 517.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "recall:0.2893\n",
            "precision:0.1215\n",
            "ndcg:0.4568\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 391/391 [00:05<00:00, 66.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 8, total_loss: 0.2764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "eval: 100%|██████████| 943/943 [00:02<00:00, 425.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "recall:0.2899\n",
            "precision:0.1208\n",
            "ndcg:0.4537\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 391/391 [00:06<00:00, 63.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 9, total_loss: 0.2709\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "eval: 100%|██████████| 943/943 [00:01<00:00, 517.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "recall:0.2915\n",
            "precision:0.1221\n",
            "ndcg:0.4577\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 391/391 [00:07<00:00, 50.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 10, total_loss: 0.2658\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "eval: 100%|██████████| 943/943 [00:01<00:00, 504.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "recall:0.2949\n",
            "precision:0.1224\n",
            "ndcg:0.4545\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "test: 100%|██████████| 943/943 [00:01<00:00, 510.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "recall:0.2989\n",
            "precision:0.1237\n",
            "ndcg:0.4592\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(1, n_epoch+1):\n",
        "    model.train()\n",
        "    total_loss= []\n",
        "    for i, batch_data in enumerate(tqdm(train_loader, desc=\"train\")):\n",
        "        users, items, labels = batch_data\n",
        "        pred = model(users, items)\n",
        "        loss = loss_function(pred, labels)\n",
        "        total_loss.append(loss.item())\n",
        "\n",
        "        # backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f\"epoch: {epoch}, total_loss: {np.mean(total_loss):.4f}\")\n",
        "\n",
        "    # validation\n",
        "    model.eval()\n",
        "    recall = np.array([])\n",
        "    precision = np.array([])\n",
        "    ndcg = np.array([])\n",
        "    for u, true in tqdm(val_true.items(), desc=\"eval\"):\n",
        "        # 유저별 소비하지 않은 아이템\n",
        "        unconsumed_items = list(set(all_items)-set(user_consumed[u]))\n",
        "        unconsumed_items = torch.tensor(unconsumed_items).to(device)\n",
        "        uu = torch.tensor([u]*len(unconsumed_items)).to(device)\n",
        "\n",
        "        # 추론\n",
        "        pred = model(uu, unconsumed_items)\n",
        "        _, pred_idx = torch.topk(pred, k=top_k)\n",
        "        top_k_items = unconsumed_items[pred_idx].tolist()\n",
        "\n",
        "        # 메트릭\n",
        "        recall=np.append(recall, get_recall(top_k_items, true, k=top_k))\n",
        "        precision=np.append(precision, get_precision(top_k_items, true, k=top_k))\n",
        "        ndcg=np.append(ndcg, get_nDCG(top_k_items, true, k=top_k))\n",
        "    print(f\"recall:{np.mean(recall):.4f}\\nprecision:{np.mean(precision):.4f}\\nndcg:{np.mean(ndcg):.4f}\")\n",
        "\n",
        "# validation\n",
        "model.eval()\n",
        "recall = np.array([])\n",
        "precision = np.array([])\n",
        "ndcg = np.array([])\n",
        "for u, true in tqdm(test_true.items(), desc=\"test\"):\n",
        "    # 유저별 소비하지 않은 아이템\n",
        "    unconsumed_items = list(set(all_items)-set(user_consumed[u]))\n",
        "    unconsumed_items = torch.tensor(unconsumed_items).to(device)\n",
        "    uu = torch.tensor([u]*len(unconsumed_items)).to(device)\n",
        "\n",
        "    # 추론\n",
        "    pred = model(uu, unconsumed_items)\n",
        "    _, pred_idx = torch.topk(pred, k=top_k)\n",
        "    top_k_items = unconsumed_items[pred_idx].tolist()\n",
        "\n",
        "    # 메트릭\n",
        "    recall=np.append(recall, get_recall(top_k_items, true, k=top_k))\n",
        "    precision=np.append(precision, get_precision(top_k_items, true, k=top_k))\n",
        "    ndcg=np.append(ndcg, get_nDCG(top_k_items, true, k=top_k))\n",
        "print(f\"recall:{np.mean(recall):.4f}\\nprecision:{np.mean(precision):.4f}\\nndcg:{np.mean(ndcg):.4f}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}